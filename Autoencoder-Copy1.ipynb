{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/Dhruv0208/Research-Project/Autoencoder.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on github\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/Dhruv0208/Research-Project/Autoencoder.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "</td></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install keras\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install imutils\n",
    "# !{sys.executable} -m pip install opencv-python\n",
    "# !{sys.executable} -m pip install sklearn\n",
    "# !{sys.executable} -m pip install --upgrade pip\n",
    "# !{sys.executable} -m pip install -q tfds-nightly tensorflow\n",
    "# !{sys.executable} -m pip install pydot\n",
    "# !{sys.executable} -m pip install graphviz\n",
    "# !{sys.executable} -m pip install keras-pos-embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from typing import Union, Dict, Tuple\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "import os\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import IPython.display as display\n",
    "from keras_pos_embd import TrigPosEmbedding\n",
    "from tensorflow.keras.layers import Dropout, Activation, LayerNormalization, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}',format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "IMAGE_SIZE = [512,512]\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern_train = f'coco/2017/1.1.0/coco-train.tfrecord*'\n",
    "file_pattern_test = f'coco/2017/1.1.0/coco-test.tfrecord*'\n",
    "file_pattern_valid = f'coco/2017/1.1.0/coco-validation.tfrecord*'\n",
    "Training_filenames = tf.data.Dataset.list_files(file_pattern_train)\n",
    "Test_filenames = tf.data.Dataset.list_files(file_pattern_test)\n",
    "Valid_filenames = tf.data.Dataset.list_files(file_pattern_valid)\n",
    "print(\"Train Tfrecords Files: \", len(Training_filenames))\n",
    "print(\"Test Tfrecords Files: \", len(Test_filenames))\n",
    "print(\"Valid Tfrecords Files: \", len(Valid_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [*IMAGE_SIZE])\n",
    "    paddings = tf.constant([[1,1], [1,1], [0,0]])\n",
    "    image = tf.pad(image, paddings, \"CONSTANT\")\n",
    "    image = tf.image.resize(image, [*IMAGE_SIZE])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description={\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string,)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(\n",
    "    serialized_example, feature_description\n",
    "    )\n",
    "    image = decode_image(example['image'])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        filenames)\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset =dataset.map(\n",
    "        partial(read_tfrecord), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames):\n",
    "    dataset = load_dataset(filenames)\n",
    "    dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(Training_filenames)\n",
    "valid_dataset = get_dataset(Valid_filenames)\n",
    "test_dataset = get_dataset(Test_filenames)\n",
    "# train_dist_datset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "# test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
    "# valid_dist_dataset = strategy.experimental_distribute_dataset(valid_dataset)\n",
    "image_batch = next(iter(train_dataset))\n",
    "def show_batch_original(image_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(4):\n",
    "        ax = plt.subplot(5,5, n+1)\n",
    "        print(image_batch[n].shape)\n",
    "        plt.imshow(image_batch[n] / 255.0)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "show_batch_original(image_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(512,512,3))\n",
    "x = layers.Conv2D(256, (1,1), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "encoded = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(encoded)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(16, (3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(32, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(64, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(64, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(128, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(256, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "decoded = layers.Conv2D(3, (3,3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "\n",
    "autoencoder = tf.keras.Model(inputs=input_img, outputs=decoded)\n",
    "middle = tf.keras.Model(inputs=input_img, outputs=encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_fn = tfa.losses.SigmoidFocalCrossEntropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_xcycwh_to_x1y1x2y2(bbox_xcycwh : np.array):\n",
    "    \n",
    "    \n",
    "    bbox_x1y1x2y2 = np.zeros_like((bbox_xcycwh))\n",
    "    bbox_x1y1x2y2[:,0] = bbox_xcycwh[:,0] - (bbox_xcycwh[:,2] / 2)\n",
    "    bbox_x1y1x2y2[:,2] = bbox_xcycwh[:,0] + (bbox_xcycwh[:,2] / 2)\n",
    "    bbox_x1y1x2y2[:,1] = bbox_xcycwh[:,1] - (bbox_xcycwh[:,3] / 2)\n",
    "    bbox_x1y1x2y2[:,3] = bbox_xcycwh[:,1] - (bbox_xcycwh[:,3] / 2)\n",
    "    bbox_x1y1x2y2 = bbox_x1y1x2y2.astype(np.int32)\n",
    "    return bbox_x1y1x2y2\n",
    "\n",
    "def intersect(box_a : tf.Tensor, box_b : tf.Tensor) -> tf.Tensor:\n",
    "    A = tf.shape(box_a)[0]\n",
    "    B = tf.shape(box_b)[0]\n",
    "    \n",
    "    tiled_box_a_xymax = tf.tile(tf.expand_dims(box_a[:,2:], axis=1), [1, B, 1])\n",
    "    tiled_box_b_xymax = tf.tile(tf.expand_dims(box_b[:,2:], axis=0), [A, 1, 1])\n",
    "    \n",
    "    above_right_corner = tf.math.minimum(tiled_box_a_xymax, tiled_box_b_xymax)\n",
    "    \n",
    "    tiled_box_a_xymin = tf.tile(tf.expand_dims(box_a[:, :2], axis=1), [1,B,1])\n",
    "    tiled_box_b_xymin = tf.tile(tf.expand_dims(box_b[:, :2], axis=0), [A,1,1])\n",
    "    upper_left_corner = tf.math.maximum(tiled_box_a_xymin, tiled_box_b_xymin)\n",
    "    \n",
    "    inter = tf.nn.relu(above_right_corner - upper_left_corner)\n",
    "    inter = inter[:, :, 0] * inter[:, :, 1]\n",
    "    return inter\n",
    "\n",
    "def overlap(box_a: tf.Tensor, box_b: tf.Tensor, return_union=False) -> tf.Tensor:\n",
    "    inter = intersect(box_a, box_b)\n",
    "    \n",
    "    area_a = (box_a[:,2] - box_a[:,0]) * (box_a[:,3] - box_a[:,1])\n",
    "    area_a = tf.tile(tf.expand_dims(area_a, axis=-1), [1, tf.shape(inter)[-2], 1])\n",
    "    \n",
    "    area_b = (box_b[:,2] - box_b[:,0]) * (box_b[:,3] - box_b[:,1])\n",
    "    area_b = tf.tile(tf.expand_dims(area_b, axis=-2), [1, tf.shape(inter)[-2], 1])\n",
    "    \n",
    "    union = area_a + area_b - inter\n",
    "    \n",
    "    \n",
    "    if return_union is False:\n",
    "        return intersect/union\n",
    "    else:\n",
    "        return inter/union, union\n",
    "    \n",
    "def merge(box_a: tf.Tensor, box_b: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    \n",
    "    A = tf.shape(box_a)[0]\n",
    "    B = tf.shape(box_b)[0]\n",
    "    \n",
    "    tiled_box_a = tf.tile(tf.expand_dims(box_a, axis=1), [1, B, 1])\n",
    "    tiled_box_b = tf.tile(tf.expand_dims(box_b, axis=0), [A, 1, 1])\n",
    "    \n",
    "    return tiled_box_a, tiled_box_b\n",
    "\n",
    "\n",
    "def xy_min_xy_max_to_xcycwh(bbox: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Convert bbox from shape [xmin, ymin, xmax, ymax] to [xc, yc, w, h]\n",
    "    Args:\n",
    "        bbox A (tf.Tensor) list a bbox (n, 4) with n the number of bbox to convert\n",
    "    Returns:\n",
    "        The converted bbox\n",
    "    \"\"\"\n",
    "    bbox_xcycwh = tf.concat([bbox[:, :2] + ((bbox[:, 2:] - bbox[:, :2]) / 2), bbox[:, 2:] - bbox[:, :2]], axis=-1)\n",
    "    return bbox_xcycwh\n",
    "\n",
    "\n",
    "\n",
    "def xcycwh_to_xy_min_xy_max(bbox: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Convert bbox from shape [xc, yc, w, h] to [xmin, ymin, xmax, ymax]\n",
    "    Args:\n",
    "        bbox A (tf.Tensor) list a bbox (n, 4) with n the number of bbox to convert\n",
    "    Returns:\n",
    "        The converted bbox\n",
    "    \"\"\"\n",
    "    bbox_xyxy = tf.concat([bbox[:, :2] - (bbox[:, 2:] / 2), bbox[:, :2] + (bbox[:, 2:] / 2)], axis=-1)\n",
    "    \n",
    "    bbox_xyxy = tf.clip_by_value(bbox_xyxy, 0.0, 1.0)\n",
    "    return bbox_xyxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKBONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.conv1 = layers.Conv2D(256, (1,1), padding='same',\n",
    "                            activation='relu', name='conv1')\n",
    "        self.conv2 = layers.Conv2D(128, (3,3), padding='same',\n",
    "                            activation='relu', name='conv2')\n",
    "        self.conv3 = layers.Conv2D(64, (3,3), padding='same',\n",
    "                            activation='relu', name='conv3')\n",
    "        self.conv4 = layers.Conv2D(64, (3,3), padding='same',\n",
    "                            activation='relu', name='conv4')\n",
    "        self.conv5 = layers.Conv2D(32, (3,3), padding='same',\n",
    "                            activation='relu', name='conv4')\n",
    "        self.conv6 = layers.Conv2D(16, (3,3), padding='same',\n",
    "                            activation='relu', name='conv6')\n",
    "        self.conv7 = layers.Conv2D(16, (3,3), padding='same',\n",
    "                            activation='relu', name='conv7')\n",
    "        self.bn1 = layers.BatchNormalization(name='bn1')\n",
    "        self.bn2 = layers.BatchNormalization(name='bn2')\n",
    "        self.bn3 = layers.BatchNormalization(name='bn3')\n",
    "        self.bn4 = layers.BatchNormalization(name='bn4')\n",
    "        self.bn5 = layers.BatchNormalization(name='bn5')\n",
    "        self.bn6 = layers.BatchNormalization(name='bn6')\n",
    "        self.maxpool = layers.MaxPooling2D((2,2), padding='same')\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Encoder and Decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim, num_heads, dropout=0.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert model_dim % num_heads == 0\n",
    "        self.head_dim = model_dim // num_heads\n",
    "\n",
    "        self.dropout = Dropout(rate=dropout)\n",
    "        \n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        in_dim = sum([shape[-1] for shape in input_shapes[:3]])\n",
    "\n",
    "        self.in_proj_weight = self.add_weight(\n",
    "            name='in_proj_kernel', shape=(in_dim, self.model_dim),\n",
    "            initializer=tf.keras.initializers.GlorotUniform(), dtype=tf.float32, trainable=True\n",
    "        )\n",
    "        self.in_proj_bias = self.add_weight(\n",
    "            name='in_proj_bias', shape=(in_dim,),\n",
    "            initializer=tf.keras.initializers.GlorotUniform(), dtype=tf.float32, trainable=True\n",
    "        )\n",
    "        self.out_proj_weight = self.add_weight(\n",
    "            name='out_proj_kernel', shape=(self.model_dim, self.model_dim),\n",
    "            initializer=tf.keras.initializers.GlorotUniform(), dtype=tf.float32, trainable=True\n",
    "        )\n",
    "        self.out_proj_bias = self.add_weight(\n",
    "            name='out_proj_bias', shape=(self.model_dim,),\n",
    "            initializer=tf.keras.initializers.GlorotUniform(), dtype=tf.float32, trainable=True\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #self.in_proj_weight = tf.Variable(\n",
    "        #    tf.zeros((in_dim, self.model_dim), dtype=tf.float32), name='in_proj_kernel')\n",
    "        #self.in_proj_bias = tf.Variable(tf.zeros((in_dim,), dtype=tf.float32),\n",
    "        #                                name='in_proj_bias')\n",
    "\n",
    "        #self.out_proj_weight = tf.Variable(\n",
    "        #    tf.zeros((self.model_dim, self.model_dim), dtype=tf.float32), name='out_proj_kernel')\n",
    "        #self.out_proj_bias = tf.Variable(\n",
    "        #    tf.zeros((self.model_dim,), dtype=tf.float32), name='out_proj_bias')\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs, attn_mask=None, key_padding_mask=None,\n",
    "             need_weights=True, training=False):\n",
    "\n",
    "        query, key, value = inputs\n",
    "\n",
    "        batch_size = tf.shape(query)[1]\n",
    "        target_len = tf.shape(query)[0]\n",
    "        source_len = tf.shape(key)[0]\n",
    "\n",
    "        W = self.in_proj_weight[:self.model_dim, :]\n",
    "        b = self.in_proj_bias[:self.model_dim]\n",
    "\n",
    "        WQ = tf.matmul(query, W, transpose_b=True) + b\n",
    "\n",
    "        W = self.in_proj_weight[self.model_dim:2*self.model_dim, :]\n",
    "        b = self.in_proj_bias[self.model_dim:2*self.model_dim]\n",
    "        WK = tf.matmul(key, W, transpose_b=True) + b\n",
    "\n",
    "        W = self.in_proj_weight[2*self.model_dim:, :]\n",
    "        b = self.in_proj_bias[2*self.model_dim:]\n",
    "        WV = tf.matmul(value, W, transpose_b=True) + b\n",
    "\n",
    "        WQ *= float(self.head_dim) ** -0.5\n",
    "        WQ = tf.reshape(WQ, [target_len, batch_size * self.num_heads, self.head_dim])\n",
    "        WQ = tf.transpose(WQ, [1, 0, 2])\n",
    "        \n",
    "        WK = tf.reshape(WK, [source_len, batch_size * self.num_heads, self.head_dim])\n",
    "        WK = tf.transpose(WK, [1, 0, 2])\n",
    "\n",
    "        WV = tf.reshape(WV, [source_len, batch_size * self.num_heads, self.head_dim])\n",
    "        WV = tf.transpose(WV, [1, 0, 2])\n",
    "        \n",
    "        attn_output_weights = tf.matmul(WQ, WK, transpose_b=True)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn_output_weights += attn_mask\n",
    "\n",
    "        \"\"\"\n",
    "        if key_padding_mask is not None:\n",
    "            attn_output_weights = tf.reshape(attn_output_weights,\n",
    "                                [batch_size, self.num_heads, target_len, source_len])\n",
    "            key_padding_mask = tf.expand_dims(key_padding_mask, 1)\n",
    "            key_padding_mask = tf.expand_dims(key_padding_mask, 2)\n",
    "            key_padding_mask = tf.tile(key_padding_mask, [1, self.num_heads, target_len, 1])\n",
    "            #print(\"before attn_output_weights\", attn_output_weights.shape)\n",
    "            attn_output_weights = tf.where(key_padding_mask,\n",
    "                                           tf.zeros_like(attn_output_weights) + float('-inf'),\n",
    "                                           attn_output_weights)\n",
    "            attn_output_weights = tf.reshape(attn_output_weights,\n",
    "                                [batch_size * self.num_heads, target_len, source_len])\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        attn_output_weights = tf.nn.softmax(attn_output_weights, axis=-1)\n",
    "        attn_output_weights = self.dropout(attn_output_weights, training=training)\n",
    "\n",
    "        attn_output = tf.matmul(attn_output_weights, WV)\n",
    "        attn_output = tf.transpose(attn_output, [1, 0, 2])\n",
    "        attn_output = tf.reshape(attn_output, [target_len, batch_size, self.model_dim])\n",
    "        attn_output = tf.matmul(attn_output, self.out_proj_weight,\n",
    "                                transpose_b=True) + self.out_proj_bias\n",
    "\n",
    "        if need_weights:\n",
    "            attn_output_weights = tf.reshape(attn_output_weights,\n",
    "                            [batch_size, self.num_heads, target_len, source_len])\n",
    "            # Retrun the average weight over the heads\n",
    "            avg_weights = tf.reduce_mean(attn_output_weights, axis=1)\n",
    "            return attn_output, avg_weights\n",
    "        \n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim=512, num_heads=8, dim_feedforward=512,\n",
    "                dropout=0.1, activation='relu', normalize_before=False,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(model_dim, num_heads, dropout=dropout,\n",
    "                                           name='self_attention')\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.activation = Activation(activation)\n",
    "        self.linear1 = Dense(dim_feedforward, name = 'linear1')\n",
    "        self.linear2 = Dense(dim_feedforward, name = 'linear2')\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-5, name = 'norm1')\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-5, name = 'norm2')\n",
    "        self.normalize_before = normalize_before\n",
    "        \n",
    "    def call(self, source, source_mask=None, source_key_padding_mask=None,\n",
    "            pos_encoding=None, training=False):\n",
    "        if pos_encoding is None:\n",
    "            query = key = source\n",
    "        else:\n",
    "            query = key = source + pos_encoding\n",
    "            \n",
    "        attn_source = self.attention((query, key, source), attn_mask=source_mask,\n",
    "                                    key_padding_mask=source_key_padding_mask, need_weights=False)\n",
    "        source += self.dropout(attn_source, training=training)\n",
    "        source = self.norm1(source)\n",
    "        \n",
    "        x = self.linear1(source)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.linear2(x)\n",
    "        source += self.dropout(x, training=training)\n",
    "        source = self.norm2(source)\n",
    "        \n",
    "        return source\n",
    "    \n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_dim=512, num_heads=8, dim_feedforward=512,\n",
    "                 dropout=0.1, activation='relu', normalize_before=False,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(model_dim, num_heads, dropout=dropout,\n",
    "                                            name='self_attn')\n",
    "        self.multihead_attn = MultiHeadAttention(model_dim, num_heads, dropout=dropout,\n",
    "                                                 name='multihead_attn')\n",
    "\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.activation = Activation(activation)\n",
    "\n",
    "        self.linear1 = Dense(dim_feedforward, name='linear1')\n",
    "        self.linear2 = Dense(model_dim, name='linear2')\n",
    "\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-5, name='norm1')\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-5, name='norm2')\n",
    "        self.norm3 = LayerNormalization(epsilon=1e-5, name='norm3')\n",
    "\n",
    "        self.normalize_before = normalize_before\n",
    "\n",
    "\n",
    "    def call(self, target, memory, target_mask=None, memory_mask=None,\n",
    "             target_key_padding_mask=None, memory_key_padding_mask=None,\n",
    "             pos_encoding=None, query_encoding=None, training=False):\n",
    "\n",
    "        query_tgt = key_tgt = target + query_encoding\n",
    "        attn_target = self.self_attn((query_tgt, key_tgt, target), attn_mask=target_mask,\n",
    "                                    key_padding_mask=target_key_padding_mask,\n",
    "                                    need_weights=False)\n",
    "        target += self.dropout(attn_target, training=training)\n",
    "        target = self.norm1(target)\n",
    "\n",
    "        query_tgt = target + query_encoding\n",
    "        key_mem = memory + pos_encoding\n",
    "        \n",
    "        attn_target2 = self.multihead_attn((query_tgt, key_mem, memory), attn_mask=memory_mask,\n",
    "                                           key_padding_mask=memory_key_padding_mask,\n",
    "                                           need_weights=False)\n",
    "        target += self.dropout(attn_target2, training=training)\n",
    "        target = self.norm2(target)\n",
    "\n",
    "        x = self.linear1(target)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.linear2(x)\n",
    "        target += self.dropout(x, training=training)\n",
    "        target = self.norm3(target)\n",
    "        \n",
    "        return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transformer Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(tf.keras.Model):\n",
    "    def __init__(self, model_dim=512, num_heads=8, dim_feedforward=512,\n",
    "                dropout=0.1, activation='relu', normalize_before=False, norm=None,\n",
    "                num_encoder_layers=6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(model_dim, num_heads, dim_feedforward,\n",
    "                                           dropout, activation, normalize_before,\n",
    "                                           name='layer_%d'%i)\n",
    "                              for i in range(num_encoder_layers)]\n",
    "        self.norm = norm\n",
    "        \n",
    "        \n",
    "    def call(self, source, mask=None, source_key_padding_mask=None,\n",
    "            pos_encoding=None, training=False):\n",
    "        \n",
    "        x = source\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, source_mask=mask, source_key_padding_mask=source_key_padding_mask,\n",
    "                     pos_encoding=pos_encoding, training=training)\n",
    "            \n",
    "        if self.norm:\n",
    "            x = self.norm(x)\n",
    "            \n",
    "            \n",
    "        return x\n",
    "    \n",
    "class TransformerDecoder(tf.keras.Model):\n",
    "    def __init__(self, model_dim=512, num_heads=8, dim_feedforward=2048,\n",
    "                dropout=0.1, activation='relu', normalize_before=False, norm=None,\n",
    "                num_decoder_layers=6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.decoder_layers = [DecoderLayer(model_dim, num_heads, dim_feedforward,\n",
    "                                          dropout, activation, normalize_before,\n",
    "                                          name='layer_%d'%i)\n",
    "                             for i in range(num_decoder_layers)]\n",
    "        self.norm = norm\n",
    "        \n",
    "    def call(self, target, memory, target_mask=None, memory_mask=None,\n",
    "            target_key_padding_mask=None, memory_key_padding_mask=None,\n",
    "            pos_encoding=None, query_encoding=None, training=False):\n",
    "        \n",
    "        x = target\n",
    "        intermediate = []\n",
    "        \n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, memory, target_mask=target_mask,\n",
    "                     memory_mask=memory_mask,\n",
    "                     target_key_padding_mask=target_key_padding_mask,\n",
    "                     memory_key_padding_mask=memory_key_padding_mask,\n",
    "                     pos_encoding=pos_encoding,\n",
    "                     query_encoding=query_encoding)\n",
    "            \n",
    "            if self.norm:\n",
    "                x = self.norm(x)\n",
    "                \n",
    "                \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbeddingSine(tf.keras.Model):\n",
    "    def __init__(self, num_pos_features=64, temperature=10000,\n",
    "                normalize=False, scale=None, eps=1e-6, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.num_pos_features = num_pos_features\n",
    "        self.temperature = temperature\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        \n",
    "        if scale is not None and normalize is False:\n",
    "            raise ValueError('normalize should be True if scale is passed')\n",
    "        if scale is None:\n",
    "            scale = 2 * np.pi\n",
    "        self.scale = scale\n",
    "        self.eps = eps\n",
    "        \n",
    "        \n",
    "    def call(self, mask):\n",
    "        not_mask = tf.cast(-mask, tf.float32)\n",
    "        y_embed = tf.math.cumsum(not_mask, axis=0)\n",
    "        x_embed = tf.math.cumsum(not_mask, axis=1)\n",
    "        \n",
    "        if self.normalize:\n",
    "            y_embed = y_embed / (y_embed[:, -1, :] + self.eps) * self.scale\n",
    "            x_embed = x_embed / (x_embed[:, :, -1] + self.eps) * self.scale\n",
    "            \n",
    "            \n",
    "        dim_t = tf.range(self.num_pos_features, dtype=tf.float32)\n",
    "        dim_t = self.temperature ** (2 * (dim_t //2 ) / self.num_pos_features)\n",
    "        \n",
    "        pos_x = x_embed[..., tf.newaxis] / dim_t\n",
    "        pos_y = y_embed[..., tf.newaxis] / dim_t\n",
    "        \n",
    "        pos_x = tf.stack([tf.math.sin(pos_x[..., 0::2]),\n",
    "                         tf.math.cos(pos_x[..., 1::2])], axis=3)\n",
    "        pos_y = tf.stack([tf.math.sin(pos_y[...,0::2]),\n",
    "                          tf.math.cos(pos_y[...,1::2])], axis=3)\n",
    "        \n",
    "        shape = [tf.shape(pos_x) for i in range(3)] + [-1]\n",
    "        pos_x = tf.reshape(pos_x, shape)\n",
    "        pos_y = tf.reshape(pos_y, shape)\n",
    "        \n",
    "        pos_emb = tf.concat([pos_y, pos_x], axis=2)\n",
    "        return pos_emb\n",
    "    \n",
    "class FixedEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_shape, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_shape = embed_shape\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='kernel', shape=self.embed_shape,\n",
    "                                 initializer=tf.keras.initializers.GlorotUniform(), trainable=True)\n",
    "\n",
    "    def call(self, x=None):\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlayers = []\n",
    "def add_nlayers(layers):\n",
    "        nlayers = [l.name for l in layers]\n",
    "def disable_batchnorm_training(model):\n",
    "    for l in model.layers:\n",
    "        if hasattr(l, \"layers\"):\n",
    "            disable_batchnorm_training(l)\n",
    "        elif isinstance(l, tf.keras.layers.BatchNormalization):\n",
    "            l.trainable = False\n",
    "\n",
    "def get_transformers_trainable_variables(model, exclude=[]):\n",
    "    transformers_variables = []\n",
    "\n",
    "    # Transformers variables\n",
    "    transformers_variables = model.get_layer(\"detr\").get_layer(\"transformer\").trainable_variables\n",
    "\n",
    "    for layer in model.layers[2:]:\n",
    "        if layer.name not in exclude:\n",
    "            transformers_variables += layer.trainable_variables\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return transformers_variables\n",
    "\n",
    "\n",
    "def get_backbone_trainable_variables(model):\n",
    "    backbone_variables = []\n",
    "    # layer [1] is the detr model including the backbone and the transformers\n",
    "\n",
    "    detr = model.get_layer(\"detr\")\n",
    "    tr_index = [l.name for l in detr.layers].index('transformer')\n",
    "\n",
    "    for l, layer in enumerate(detr.layers):\n",
    "        if l != tr_index:\n",
    "            backbone_variables += layer.trainable_variables\n",
    "\n",
    "    return backbone_variables\n",
    "\n",
    "\n",
    "def get_nlayers_trainables_variables(model, nlayers_names):\n",
    "    nlayers_variables = []\n",
    "    for nlayer_name in nlayers_names:\n",
    "        nlayers_variables += model.get_layer(nlayer_name).trainable_variables\n",
    "    return nlayers_variables\n",
    "\n",
    "\n",
    "def get_trainable_variables(model):\n",
    "\n",
    "    disable_batchnorm_training(model)\n",
    "\n",
    "    backbone_variables = []\n",
    "    transformers_variables = []\n",
    "    nlayers_variables = []\n",
    "\n",
    "\n",
    "    # Retrieve the gradient for each trainable variables\n",
    "    backbone_variables = get_backbone_trainable_variables(model)\n",
    "    transformers_variables = get_transformers_trainable_variables(model, exclude=nlayers)\n",
    "    nlayers_variables = get_nlayers_trainables_variables(model, nlayers)\n",
    "\n",
    "    \n",
    "    return backbone_variables, transformers_variables, nlayers_variables\n",
    "\n",
    "\n",
    "def setup_optimizers(model):\n",
    "    \"\"\" Method call by the Scheduler to init user data\n",
    "    \"\"\"\n",
    "    @tf.function\n",
    "    def get_backbone_learning_rate():\n",
    "        return 1e-5\n",
    "\n",
    "    @tf.function\n",
    "    def get_transformers_learning_rate():\n",
    "        return 1e-4\n",
    "\n",
    "    @tf.function\n",
    "    def get_nlayers_learning_rate():\n",
    "        return 1e-4\n",
    "\n",
    "    # Disable batch norm on the backbone\n",
    "    disable_batchnorm_training(model)\n",
    "\n",
    "    # Optimizers\n",
    "    backbone_optimizer = tf.keras.optimizers.Adam(learning_rate=get_backbone_learning_rate, clipnorm=0.001)\n",
    "    transformers_optimizer = tf.keras.optimizers.Adam(learning_rate=get_transformers_learning_rate, clipnorm=0.001)\n",
    "    nlayers_optimizer = tf.keras.optimizers.Adam(learning_rate=get_nlayers_learning_rate, clipnorm=0.001)\n",
    "\n",
    "    # Set trainable variables\n",
    "\n",
    "    backbone_variables, transformers_variables, nlayers_variables = [], [], []\n",
    "\n",
    "    backbone_variables = get_backbone_trainable_variables(model)\n",
    "    transformers_variables = get_transformers_trainable_variables(model, exclude=nlayers)\n",
    "    nlayers_variables = get_nlayers_trainables_variables(model, nlayers)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"backbone_optimizer\": backbone_optimizer,\n",
    "        \"transformers_optimizer\": transformers_optimizer,\n",
    "        \"nlayers_optimizer\": nlayers_optimizer,\n",
    "\n",
    "        \"backbone_variables\": backbone_variables,\n",
    "        \"transformers_variables\": transformers_variables,\n",
    "        \"nlayers_variables\": nlayers_variables,\n",
    "    }\n",
    "\n",
    "\n",
    "def gather_gradient(model, optimizers, total_loss, tape):\n",
    "\n",
    "    backbone_variables, transformers_variables, nlayers_variables = get_trainable_variables(model)\n",
    "    trainables_variables = backbone_variables + transformers_variables + nlayers_variables\n",
    "\n",
    "    gradients = tape.gradient(total_loss, trainables_variables)\n",
    "\n",
    "    # Retrieve the gradients from the tap\n",
    "    backbone_gradients = gradients[:len(optimizers[\"backbone_variables\"])]\n",
    "    transformers_gradients = gradients[len(optimizers[\"backbone_variables\"]):len(optimizers[\"backbone_variables\"])+len(optimizers[\"transformers_variables\"])]\n",
    "    nlayers_gradients = gradients[len(optimizers[\"backbone_variables\"])+len(optimizers[\"transformers_variables\"]):]\n",
    "\n",
    "    gradient_steps = {}\n",
    "\n",
    "    gradient_steps[\"backbone\"] = {\"gradients\": backbone_gradients}\n",
    "    gradient_steps[\"transformers\"] = {\"gradients\": transformers_gradients}\n",
    "    gradient_steps[\"nlayers\"] = {\"gradients\": nlayers_gradients}\n",
    "\n",
    "    \n",
    "\n",
    "    return gradient_steps\n",
    "\n",
    "\n",
    "\n",
    "def aggregate_grad_and_apply(name, optimizers, gradients, step):\n",
    "\n",
    "    gradient_aggregate = None\n",
    "    if target_batch is not None:\n",
    "        gradient_aggregate = int(target_batch // batch_size)\n",
    "\n",
    "    gradient_name = \"{}_gradients\".format(name)\n",
    "    optimizer_name = \"{}_optimizer\".format(name)\n",
    "    variables_name = \"{}_variables\".format(name)\n",
    "    train_part_name = \"train_{}\".format(name)\n",
    "\n",
    "    if getattr(train_part_name):\n",
    "\n",
    "        # Init the aggregate gradient\n",
    "        if gradient_aggregate is not None and step % gradient_aggregate == 0:\n",
    "            optimizers[gradient_name] = [tf.zeros_like(tv) for tv in optimizers[variables_name]]\n",
    "\n",
    "\n",
    "        if gradient_aggregate is not None:\n",
    "            # Aggregate the gradient\n",
    "            optimizers[gradient_name] = [(gradient+n_gradient) if n_gradient is not None else None for gradient, n_gradient in zip(optimizers[gradient_name], gradients) ]\n",
    "        else:\n",
    "            optimizers[gradient_name] = gradients\n",
    "\n",
    "        # Apply gradient if no gradient aggregate or if we finished gathering gradient oversteps\n",
    "        if gradient_aggregate is None or (step+1) %  gradient_aggregate == 0:\n",
    "            optimizers[optimizer_name].apply_gradients(zip(optimizers[gradient_name], optimizers[variables_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hungarian Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hungarian_matching(t_bbox, t_class, p_bbox, p_class, fcost_class=1,\n",
    "                      fcost_bbox=5, fcost_giou=2, slices_pred=True):\n",
    "    if slice_preds:\n",
    "        size = tf.cast(t_bbox[0][0], tf.int32)\n",
    "        t_bbox = tf.slice(t_bbo, [1, 0], [size, 4])\n",
    "        t_class = tf.slice(t_class, [1, 0], [size, -1])\n",
    "        t_class = tf.squeeze(t_class, axis=-1)\n",
    "        \n",
    "        \n",
    "    p_bbox_xy = xcycwh_to_xy_min_xy_max(p_bbox)\n",
    "    t_bbox_xy = xcycwh_to_xy_min_xy_max(t_bbox)\n",
    "    \n",
    "    softmax = tf.nn.softmax(p_class)\n",
    "    \n",
    "    cost_class = -tf.gather(softmax, t_class, axis=1)\n",
    "    _p_bbox, _t_bbox = merge(p_bbox, t_bbox)\n",
    "    cost_bbox = tf.norm(_p_bbox * _t_bbox, ord=1, axis=-1)\n",
    "    \n",
    "    \n",
    "    iou, union = overlap(p_bbox_xy, t_bbox_xy, return_union=True)\n",
    "    _p_bbox_xy, _t_bbox_xy = merge(p_bbox_xy, t_bbox_xy)\n",
    "    top_left = tf.math.minimum(_p_bbox_xy[:, :, :2], _t_bbox_xy[:, :, :2])\n",
    "    bottom_right = tf.math.maximum(_p_bbox_xy[:, :, 2:], _t_bbox_xy[:, :, 2:])\n",
    "    size = tf.nn.relu(bottom_right*top_left)\n",
    "    area = size[:,:,0]*size[:,:,1]\n",
    "    cost_giou = -(iou - (area-union) / area)\n",
    "    \n",
    "    cost_matrix = fcost_bbox * cost_bbox + fcost_class * cost_class + fcost_giou * cost_giou\n",
    "    \n",
    "    \n",
    "    selectors = tf.numpy_function(np_tf_linear_sum_assignment, [cost_matrix],\n",
    "                                 [tf.int64, tf.int64, tf.bool, tf.bool])\n",
    "    target_indices = selectors[0]\n",
    "    pred_indices = selectors[1]\n",
    "    target_selector = selectors[2]\n",
    "    pred_selector = selectors[3]\n",
    "    \n",
    "    return pred_indices, target_indices, pred_selector, target_selector, t_bbox, t_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Functions for getting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_losss(losses):\n",
    "    \"\"\"\n",
    "    Get model total losss including auxiliary loss\n",
    "    \"\"\"\n",
    "    train_loss = [\"label_cost\", \"giou_loss\", \"l1_loss\"]\n",
    "    loss_weights = [1, 2, 5]\n",
    "\n",
    "    total_loss = 0\n",
    "    for key in losses:\n",
    "        selector = [l for l, loss_name in enumerate(train_loss) if loss_name in key]\n",
    "        if len(selector) == 1:\n",
    "            #print(\"Add to the total loss\", key, losses[key], loss_weights[selector[0]])\n",
    "            total_loss += losses[key]*loss_weights[selector[0]]\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def get_losses(m_outputs, t_bbox, t_class):\n",
    "    losses = get_detr_losses(m_outputs, t_bbox, t_class)\n",
    "\n",
    "    # Get auxiliary loss for each auxiliary output\n",
    "    if \"aux\" in m_outputs:\n",
    "        for a, aux_m_outputs in enumerate(m_outputs[\"aux\"]):\n",
    "            aux_losses = get_detr_losses(aux_m_outputs, t_bbox, t_class, suffix=\"_{}\".format(a))\n",
    "            losses.update(aux_losses)\n",
    "    \n",
    "    # Compute the total loss\n",
    "    total_loss = get_total_losss(losses)\n",
    "\n",
    "    return total_loss, losses\n",
    "\n",
    "\n",
    "def loss_labels(p_bbox, p_class, t_bbox, t_class, t_indices, p_indices, t_selector, p_selector, background_class=0):\n",
    "\n",
    "    neg_indices = tf.squeeze(tf.where(p_selector == False), axis=-1)\n",
    "    neg_p_class = tf.gather(p_class, neg_indices)\n",
    "    neg_t_class = tf.zeros((tf.shape(neg_p_class)[0],), tf.int64) + background_class\n",
    "    \n",
    "    neg_weights = tf.zeros((tf.shape(neg_indices)[0],)) + 0.1\n",
    "    pos_weights = tf.zeros((tf.shape(t_indices)[0],)) + 1.0\n",
    "    weights = tf.concat([neg_weights, pos_weights], axis=0)\n",
    "    \n",
    "    pos_p_class = tf.gather(p_class, p_indices)\n",
    "    pos_t_class = tf.gather(t_class, t_indices)\n",
    "\n",
    "    #############\n",
    "    # Metrics\n",
    "    #############\n",
    "    # True negative\n",
    "    cls_neg_p_class = tf.argmax(neg_p_class, axis=-1)\n",
    "    true_neg  = tf.reduce_mean(tf.cast(cls_neg_p_class == background_class, tf.float32))\n",
    "    # True positive\n",
    "    cls_pos_p_class = tf.argmax(pos_p_class, axis=-1)\n",
    "    true_pos = tf.reduce_mean(tf.cast(cls_pos_p_class != background_class, tf.float32))\n",
    "    # True accuracy\n",
    "    cls_pos_p_class = tf.argmax(pos_p_class, axis=-1)\n",
    "    pos_accuracy = tf.reduce_mean(tf.cast(cls_pos_p_class == pos_t_class, tf.float32))\n",
    "\n",
    "    targets = tf.concat([neg_t_class, pos_t_class], axis=0)\n",
    "    preds = tf.concat([neg_p_class, pos_p_class], axis=0)\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(targets, preds)\n",
    "    loss = tf.reduce_sum(loss * weights) / tf.reduce_sum(weights)\n",
    "\n",
    "    return loss, true_neg, true_pos, pos_accuracy\n",
    "\n",
    "\n",
    "def loss_boxes(p_bbox, p_class, t_bbox, t_class, t_indices, p_indices, t_selector, p_selector):\n",
    "    #print(\"------\")\n",
    "    p_bbox = tf.gather(p_bbox, p_indices)\n",
    "    t_bbox = tf.gather(t_bbox, t_indices)\n",
    "\n",
    "\n",
    "    p_bbox_xy = bbox.xcycwh_to_xy_min_xy_max(p_bbox)\n",
    "    t_bbox_xy = bbox.xcycwh_to_xy_min_xy_max(t_bbox)\n",
    "\n",
    "    l1_loss = tf.abs(p_bbox-t_bbox)\n",
    "    l1_loss = tf.reduce_sum(l1_loss) / tf.cast(tf.shape(p_bbox)[0], tf.float32)\n",
    "\n",
    "    iou, union = bbox.jaccard(p_bbox_xy, t_bbox_xy, return_union=True)\n",
    "\n",
    "    _p_bbox_xy, _t_bbox_xy = bbox.merge(p_bbox_xy, t_bbox_xy)\n",
    "    top_left = tf.math.minimum(_p_bbox_xy[:,:,:2], _t_bbox_xy[:,:,:2])\n",
    "    bottom_right =  tf.math.maximum(_p_bbox_xy[:,:,2:], _t_bbox_xy[:,:,2:])\n",
    "    size = tf.nn.relu(bottom_right - top_left)\n",
    "    area = size[:,:,0] * size[:,:,1]\n",
    "    giou = (iou - (area - union) / area)\n",
    "    loss_giou = 1 - tf.linalg.diag_part(giou)\n",
    "\n",
    "    loss_giou = tf.reduce_sum(loss_giou) / tf.cast(tf.shape(p_bbox)[0], tf.float32)\n",
    "\n",
    "    return loss_giou, l1_loss\n",
    "\n",
    "def get_detr_losses(m_outputs, target_bbox, target_label, suffix=\"\"):\n",
    "\n",
    "    predicted_bbox = m_outputs[\"pred_boxes\"]\n",
    "    predicted_label = m_outputs[\"pred_logits\"]\n",
    "\n",
    "    all_target_bbox = []\n",
    "    all_target_class = []\n",
    "    all_predicted_bbox = []\n",
    "    all_predicted_class = []\n",
    "    all_target_indices = []\n",
    "    all_predcted_indices = []\n",
    "    all_target_selector = []\n",
    "    all_predcted_selector = []\n",
    "\n",
    "    t_offset = 0\n",
    "    p_offset = 0\n",
    "\n",
    "    for b in range(predicted_bbox.shape[0]):\n",
    "\n",
    "        p_bbox, p_class, t_bbox, t_class = predicted_bbox[b], predicted_label[b], target_bbox[b], target_label[b]\n",
    "        t_indices, p_indices, t_selector, p_selector, t_bbox, t_class = hungarian_matching(t_bbox, t_class, p_bbox, p_class, slice_preds=True)\n",
    "\n",
    "        t_indices = t_indices + tf.cast(t_offset, tf.int64)\n",
    "        p_indices = p_indices + tf.cast(p_offset, tf.int64)\n",
    "\n",
    "        all_target_bbox.append(t_bbox)\n",
    "        all_target_class.append(t_class)\n",
    "        all_predicted_bbox.append(p_bbox)\n",
    "        all_predicted_class.append(p_class)\n",
    "        all_target_indices.append(t_indices)\n",
    "        all_predcted_indices.append(p_indices)\n",
    "        all_target_selector.append(t_selector)\n",
    "        all_predcted_selector.append(p_selector)\n",
    "\n",
    "        t_offset += tf.shape(t_bbox)[0]\n",
    "        p_offset += tf.shape(p_bbox)[0]\n",
    "\n",
    "    all_target_bbox = tf.concat(all_target_bbox, axis=0)\n",
    "    all_target_class = tf.concat(all_target_class, axis=0)\n",
    "    all_predicted_bbox = tf.concat(all_predicted_bbox, axis=0)\n",
    "    all_predicted_class = tf.concat(all_predicted_class, axis=0)\n",
    "    all_target_indices = tf.concat(all_target_indices, axis=0)\n",
    "    all_predcted_indices = tf.concat(all_predcted_indices, axis=0)\n",
    "    all_target_selector = tf.concat(all_target_selector, axis=0)\n",
    "    all_predcted_selector = tf.concat(all_predcted_selector, axis=0)\n",
    "\n",
    "\n",
    "    label_cost, true_neg, true_pos, pos_accuracy = loss_labels(\n",
    "        all_predicted_bbox,\n",
    "        all_predicted_class,\n",
    "        all_target_bbox,\n",
    "        all_target_class,\n",
    "        all_target_indices,\n",
    "        all_predcted_indices,\n",
    "        all_target_selector,\n",
    "        all_predcted_selector,\n",
    "        background_class=0,\n",
    "    )\n",
    "\n",
    "    giou_loss, l1_loss = loss_boxes(\n",
    "        all_predicted_bbox,\n",
    "        all_predicted_class,\n",
    "        all_target_bbox,\n",
    "        all_target_class,\n",
    "        all_target_indices,\n",
    "        all_predcted_indices,\n",
    "        all_target_selector,\n",
    "        all_predcted_selector\n",
    "    )\n",
    "\n",
    "    label_cost = label_cost\n",
    "    giou_loss = giou_loss\n",
    "    l1_loss = l1_loss\n",
    "\n",
    "    return {\n",
    "        \"label_cost{}\".format(suffix): label_cost,\n",
    "        \"true_neg{}\".format(suffix): true_neg,\n",
    "        \"true_pos{}\".format(suffix): true_pos,\n",
    "        \"pos_accuracy{}\".format(suffix): pos_accuracy,\n",
    "        \"giou_loss{}\".format(suffix): giou_loss,\n",
    "        \"l1_loss{}\".format(suffix): l1_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, model_dim=512, num_heads=8, num_encoder_layers=6,\n",
    "                num_decoder_layers=6, dim_feedforward=512, dropout=0.1,\n",
    "                activation='relu', normalize_before=False, **kwargs):\n",
    "        super().__init__(*kwargs)\n",
    "        \n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        encoder_norm = LayerNormalization(epsilon=1e-5, name='norm_pre') if normalize_before else None\n",
    "        self.encoder = TransformerEncoder(model_dim, num_heads, dim_feedforward,\n",
    "                                         dropout, activation, normalize_before, encoder_norm,\n",
    "                                         num_encoder_layers, name='encoder')\n",
    "        decoder_norm = LayerNormalization(epsilon=1e-5, name='norm')\n",
    "        self.decoder = TransformerDecoder(model_dim, num_heads, dim_feedforward,\n",
    "                                         dropout, activation, normalize_before, decoder_norm,\n",
    "                                         num_decoder_layers, name='decoder')\n",
    "        \n",
    "    def call(self, source, mask, query_encoding, pos_encoding, training=False):\n",
    "        batch_size, rows, cols = [tf.shape(source)[i] for i in range(3)]\n",
    "        source = tf.reshape(source, [batch_size, -1, self.model_dim])\n",
    "        source = tf.transpose(source, [1,0,2])\n",
    "            \n",
    "        pos_encoding = tf.reshape(pos_encoding, [batch_size, -1, self.model_dim])\n",
    "        pos_encoding = tf.transpose(source, [1,0,2])\n",
    "            \n",
    "        query_encoding = tf.expand_dims(query_encoding, axis=1)\n",
    "        query_encoding = tf.tile(query_encoding, [1, batch_size, 1])\n",
    "            \n",
    "        mask = tf.reshape(mask, [batch_size, -1])\n",
    "            \n",
    "        target = tf.zeros_like(query_encoding)\n",
    "        memory = self.encoder(source, source_key_padding_mask=mask,\n",
    "                                 pos_encoding=pos_encoding, training=training)\n",
    "        hs = self.decoder(source, memory, memory_key_padding_mask=mask,\n",
    "                             pos_encoding=pos_encoding, query_encoding=query_encoding,\n",
    "                             training=training)\n",
    "            \n",
    "        hs = tf.transpose(hs)\n",
    "        memory = tf.transpose(memory, [1,0,2])\n",
    "        memory = tf.reshape(memory, [batch_size, rows, cols, self.model_dim])\n",
    "            \n",
    "        return hs, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionTransformer(tf.keras.Model):\n",
    "    def __init__(self, num_classes=91, num_queries=100,\n",
    "                backbone=None,\n",
    "                pos_encoder=None,\n",
    "                transformer=None,\n",
    "                num_encoder_layers=6,\n",
    "                num_decoder_layers=6,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.num_queries = num_queries\n",
    "        self.backbone = BackBone(name='backbone')\n",
    "        self.transformer = Transformer(name = 'transformer', num_encoder_layers=num_encoder_layers,\n",
    "                                      num_decoder_layers=num_decoder_layers)\n",
    "        \n",
    "        self.model_dim = self.transformer.model_dim\n",
    "        \n",
    "        self.pos_encoder = tf.keras.layers.Embedding(input_dim=self.model_dim // 2, output_dim=64, name=\"position_embedding_sine\")\n",
    "        \n",
    "        self.input_proj = tf.keras.layers.Conv2D(self.model_dim, kernel_size=1,\n",
    "                                                name='input_proj')\n",
    "        \n",
    "        self.query_embed = FixedEmbedding((num_queries, self.model_dim), \n",
    "                                                     name='query_embed')\n",
    "        self.class_embed = Dense(num_classes, name='classes_embed')\n",
    "        self.bbox_embed_linear1 = Dense(self.model_dim, name='bbox_embed_0')\n",
    "        self.bbox_embed_linear2 = Dense(self.model_dim, name='bbox_embed_1')\n",
    "        self.bbox_embed_linear3 = Dense(4, name='bbox_embed_2')\n",
    "        \n",
    "        self.activation = tf.keras.layers.ReLU()\n",
    "        \n",
    "    def downsample_masks(self, mask, x):\n",
    "        masks = tf.cast(masks, tf.int32)\n",
    "        masks = tf.expand_dims(mask, -1)\n",
    "        masks = tf.compat.v1.image.resize_nearest_neighbour(masks, \n",
    "                                                            tf.shape(x)[1:3],\n",
    "                                                           align_corners=False,\n",
    "                                                           half_pixel_centers=False)\n",
    "        masks = tf.squeeze(masks, -1)\n",
    "        masks = tf.cast(masks, tf.bool)\n",
    "        return masks\n",
    "    \n",
    "    def call(self, inp, training=True, post_process=False):\n",
    "        x, masks = inp\n",
    "        x = self.backbone(x, training=training)\n",
    "        masks = self.downsample_masks(masks, x)\n",
    "        \n",
    "        pos_encoding = self.pos_encoder(masks)\n",
    "        \n",
    "        hs = self.transformer(self.input_proj(x), masks, self.query_embed(None),\n",
    "                             pos_encoding, training=training)[0]\n",
    "        \n",
    "        outputs_class = self.class_embed(hs)\n",
    "        \n",
    "        \n",
    "        box_ftmps = self.activation(self.bbox_embed_linear1(hs))\n",
    "        box_ftmps = self.activation(self.bbox_embed_linear2(box_ftmps))\n",
    "        outputs_coord = tf.sigmoid(self.bbox_embed_linear3(box_ftmps))\n",
    "        \n",
    "        output = {'pred_logits' : outputs_class[-1],\n",
    "                  'pred_boxes' : outputs_coord[-1]}\n",
    "        \n",
    "        if post_process:\n",
    "            output = self.post_process(output)\n",
    "        return output\n",
    "    \n",
    "    def build(self, input_shape=None, **kwargs):\n",
    "        if input_shape is None:\n",
    "            input_shape = [(None, None, None, 3), (None, None, None)]\n",
    "        super().build(input_shape, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heads_nlayers(DetectionTransformer, nb_classes=91):\n",
    "    image_input = tf.keras.layers.Input(shape=(512, 512, 3))\n",
    "    class_layer = tf.keras.layers.Dense(91, activation='relu', name=\"class_layer\")\n",
    "    position_layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(256, activation = \"relu\"),\n",
    "            tf.keras.layers.Dense(4, activation = \"sigmoid\"),\n",
    "        ], name=\"postion_layer\")\n",
    "        \n",
    "    \n",
    "    add_nlayers([class_layer, position_layer])\n",
    "        \n",
    "    transformer_output = DetectionTransformer(image_input)\n",
    "    class_preds =  class_layer(transformer_output)\n",
    "    position_preds = position_layer(transformer_output)\n",
    "        \n",
    "    outputs = {'preds_logits' : class_preds[-1],\n",
    "                   'pred_boxes' : position_preds[-1]}\n",
    "    outputs[\"aux\"] = [{\"pred_logits\" : class_preds[i],\n",
    "                          \"pred_boxes\" : position_preds[i]} \n",
    "                         for i in range(0,5)]\n",
    "        \n",
    "    n_DetectionTransformer = tf.keras.Model(image_input, outputs,\n",
    "                                               name=\"transformer_fine_tuning\")\n",
    "        \n",
    "    return n_DetectionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(nb_classes=91, num_decoder_layers=6, num_encoder_layers=6):\n",
    "    image_input = tf.keras.Input((512, 512, 3))\n",
    "    detr = DetectionTransformer(num_encoder_layers=6, num_decoder_layers=6)\n",
    "    \n",
    "    backbone = detr.get_layer(\"backbone\")\n",
    "    transformer = detr.get_layer(\"transformer\")\n",
    "    position_embedding_sine = detr.get_layer(\"position_embedding_sine\")\n",
    "    input_proj = detr.get_layer('input_proj')\n",
    "    query_embed = detr.get_layer('query_embed')\n",
    "    class_embed = detr.get_layer('query_embed')\n",
    "    bbox_embed_linear1 = detr.get_layer('bbox_embed_0')\n",
    "    bbox_embed_linear2 = detr.get_layer('bbox_embed_1')\n",
    "    bbox_embed_linear3 = detr.get_layer('bbox_embed_2')\n",
    "    activation = detr.get_layer(\"re_lu\")\n",
    "    x = backbone(image_input)\n",
    "    masks = tf.zeros((tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]))\n",
    "    pos_encoding = position_embedding_sine(masks)\n",
    "    hs = transformer(input_proj(x), masks, query_embed(None), pos_encoding)[0]\n",
    "    detr = tf.keras.Model(image_input, hs, name=\"detr\")\n",
    "    add_heads_nlayers(detr, nb_classes)\n",
    "    transformer_output = detr(image_input)\n",
    "    outputs_class = class_embed(tranformer_output)\n",
    "    box_ftmps = activation(bbox_embed_linear1(tranformer_output))\n",
    "    box_ftmps = activation(bbox_embed_linear2(box_ftmps))\n",
    "    outputs_coord = tf.sigmoid(bbox_embed_linear3(box_ftmps))\n",
    "    outputs={}\n",
    "    output = {'pred_logits': outputs_class[-1],\n",
    "             'pred_boxes': outputs_coord[-1]}\n",
    "    \n",
    "    output[\"aux\"] = []\n",
    "    for i in range(0, num_decoder_layers - 1):\n",
    "        out_class = outputs_class[i]\n",
    "        pred_boxes = outputs_coord[i]\n",
    "        output[\"aux\"].append({\n",
    "            \"pred_logits\": out_class,\n",
    "            \"pred_boxes\": pred_boxes\n",
    "        })\n",
    "        \n",
    "    return tf.keras.Model(image_input, output, name=\"detr_finetuning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, images, t_bbox, t_class, optimizers):\n",
    "    gradient_aggregate=1\n",
    "    \n",
    "    with tf.GradientTape() as Tape:\n",
    "        m_outputs = model(images, training=True)\n",
    "        total_loss = get_losses(m_outputs, t_bbox, t_class)\n",
    "        total_loss = total_loss/gradient_aggregate\n",
    "        \n",
    "    gradient_steps = gather_gradient(model, optimizers, total_loss, tape)\n",
    "    return m_outputs, total_loss, gradient_steps\n",
    "\n",
    "def fit(model, train_dt, optimizers, epoch_nb, class_names):\n",
    "    gradient_aggregate = None\n",
    "    t = None\n",
    "    for epoch_step, (images, t_bbox, t_class) in enumerate(train_dt):\n",
    "        m_outputs, total_loss, gradient_steps = train_step(model, images, t_bbox, t_class, optimizers)\n",
    "        for name in gradient_steps:\n",
    "            aggregate_grad_and_apple(name, optimizers, gradient_steps[name][\"gradients\"], epoch_step)\n",
    "            \n",
    "        if epoch_step %100 == 0:\n",
    "            t = t if t is not None else time.time()\n",
    "            print(f\"Epoch: [{epoch_nb}], \\t Step: [{epoch_steps}], \\t giou: [{giou_loss}], \\t l1 : [{l1_loss}], \\t time: [{elapsed: .2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "from skimage.color import gray2rgb\n",
    "from random import sample, shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASS_NAME = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush', \"back\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_labels(images: tf.Tensor, t_bbox: tf.Tensor, t_class: tf.Tensor):\n",
    "    \"\"\" Pad the bbox by adding [0, 0, 0, 0] at the end\n",
    "    and one header to indicate how maby bbox are set.\n",
    "    Do the same with the labels. \n",
    "    \"\"\"\n",
    "    nb_bbox = tf.shape(t_bbox)[0]\n",
    "\n",
    "    bbox_header = tf.expand_dims(nb_bbox, axis=0)\n",
    "    bbox_header = tf.expand_dims(bbox_header, axis=0)\n",
    "    bbox_header = tf.pad(bbox_header, [[0, 0], [0, 3]])\n",
    "    bbox_header = tf.cast(bbox_header, tf.float32)\n",
    "    cls_header = tf.constant([[0]], dtype=tf.int64)\n",
    "\n",
    "    # Padd bbox and class\n",
    "    t_bbox = tf.pad(t_bbox, [[0, 100 - 1 - nb_bbox], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    t_class = tf.pad(t_class, [[0, 100 - 1 - nb_bbox], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "    t_bbox = tf.concat([bbox_header, t_bbox], axis=0)\n",
    "    t_class = tf.concat([cls_header, t_class], axis=0)\n",
    "\n",
    "    return images, t_bbox, t_class\n",
    "def get_coco_labels(coco, img_id, image_shape, augmentation):\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    \n",
    "    bbox = []\n",
    "    t_class = []\n",
    "    crowd_bbox = 0\n",
    "    \n",
    "    for a, ann in enumerate(anns):\n",
    "        bbox_x, bbox_y, bbox_w, bbox_h = ann['bbox']\n",
    "        \n",
    "        t_cls = ann[\"category_id\"]\n",
    "        if ann[\"iscrowd\"]:\n",
    "            crowd_bbox = 1\n",
    "            \n",
    "        x_center = bbox_x + float(bbox_w / 2)\n",
    "        y_center = bbox_y + float(bbox_h / 2)\n",
    "        x_center = x_center / float(image_shape[1])\n",
    "        y_center = y_center / float(image_shape[0])\n",
    "        \n",
    "        bbox.append([x_center, y_center, bbox_w, bbox_h])\n",
    "        t_class.append([t_cls])\n",
    "        \n",
    "    bbox = np.array(bbox)\n",
    "    t_class = np.array(t_class)\n",
    "    \n",
    "    return bbox.astype(np.float32), t_class.astype(np.int32), crowd_bbox\n",
    "\n",
    "def get_coco_from_id(coco_id, coco, augmentation, config, img_dir):\n",
    "    img = coco.loadImgs([coco_id])[0]\n",
    "    filne_name = img['file_name']\n",
    "    image_path = os.path.join(img_dir, filne_name)\n",
    "    image = imageio.imread(image_path)\n",
    "    if len(image.shape) == 2: image = gray2rgb(image)\n",
    "    t_bbox, t_class, is_crowd = get_coco_labels(coco, img['id'], image.shape, augmentation)\n",
    "    image = processing.normalized_images(image, config)   \n",
    "    image = image.astype(np.float32)\n",
    "    t_bbox = t_bbox.astype(np.float32)\n",
    "    t_class = t_class.astype(np.int64)\n",
    "    is_crowd = np.array(is_crowd, dtype=np.int64)\n",
    "    return image, t_bbox, t_class, is_crowd\n",
    "\n",
    "def load_coco_dataset(batch_size, ann_dir, ann_file, img_dir, augmentation=False):\n",
    "    ann_dir = ann_dir\n",
    "    ann_file = ann_file\n",
    "    img_dir = img_dir\n",
    "    background_class = 0\n",
    "\n",
    "    coco = COCO(ann_file)\n",
    "    cats = coco.loadCats(coco.getCatIds())\n",
    "    # Get the max class ID\n",
    "    max_id = np.array([cat[\"id\"] for cat in cats]).max()\n",
    "    class_names = [\"N/A\"] * (max_id + 2) # + 2 for the background class\n",
    "    # Add the backgrund class at the end\n",
    "    class_names[-1] = \"back\"\n",
    "    background_class = max_id + 1\n",
    "    for cat in cats:\n",
    "        class_names[cat[\"id\"]] = cat[\"name\"]\n",
    "        \n",
    "    def numpy_fc(idx, fc, outputs_types=(tf.float32, tf.float32, tf.int64), **params):\n",
    "        def _np_function(_idx):\n",
    "            return fc(_idx, **params)\n",
    "        return tf.numpy_function(_np_function, [idx], outputs_types)\n",
    "\n",
    "    # Setup the data pipeline\n",
    "    img_ids = coco.getImgIds()\n",
    "    shuffle(img_ids)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(img_ids)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    outputs_types=(tf.float32, tf.float32, tf.int64, tf.int64)\n",
    "    dataset = dataset.map(lambda idx: numpy_fc(\n",
    "        idx, get_coco_from_id, outputs_types=outputs_types, coco=coco, augmentation=augmentation, img_dir=img_dir)\n",
    "    , num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.filter(lambda imgs, tbbox, tclass, iscrowd: tf.shape(tbbox)[0] > 0 and iscrowd != 1)\n",
    "    dataset = dataset.map(lambda imgs, tbbox, tclass, iscrowd: (imgs, tbbox, tclass), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.map(pad_labels, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(32)\n",
    "    \n",
    "    return dataset, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dt, coco_class_names = load_coco_dataset(batch_size=1, ann_dir='./annotations_trainval2017/annotations',\n",
    "#                                                 ann_file='./annotations_trainval2017/annotations/instances_train2017.json', img_dir='./train2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The last dimension of the inputs to `Dense` should be defined. Found `None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f677807025d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m91\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_decoder_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_encoder_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-03a62fbed67f>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(nb_classes, num_decoder_layers, num_encoder_layers)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdetr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"detr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0madd_heads_nlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtransformer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moutputs_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranformer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-546b89f282d8>\u001b[0m in \u001b[0;36madd_heads_nlayers\u001b[0;34m(DetectionTransformer, nb_classes)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtransformer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetectionTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mclass_preds\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mclass_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mposition_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    926\u001b[0m                                                 input_list)\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m       raise ValueError('The last dimension of the inputs to `Dense` '\n\u001b[0m\u001b[1;32m   1169\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m   1170\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The last dimension of the inputs to `Dense` should be defined. Found `None`."
     ]
    }
   ],
   "source": [
    "detr = get_model(nb_classes=91, num_decoder_layers=6, num_encoder_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in detr.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checkpoint = tf.train.Checkpoint(optimizer=optimizer, model = autoencoder)\n",
    "# epochs = 2\n",
    "# for epoch in range(epochs):\n",
    "#     print(\"\\n Start of epoch %d\" % (epoch,))\n",
    "#     for step, x_batch_train in enumerate(train_dataset):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             predictions = autoencoder(x_batch_train, training=True)\n",
    "#             loss_value = loss_fn(predictions, x_batch_train)\n",
    "            \n",
    "#         grads = tape.gradient(loss_value, autoencoder.trainable_weights)\n",
    "#         optimizer.apply_gradients(zip(grads, autoencoder.trainable_weights))\n",
    "# #         if step&10000 == 0:\n",
    "# #             checkpoint.save(checkpoint_prefix)\n",
    "#         if step%100 == 0:\n",
    "#             print(\"Seen so far: %s samples\" % ((step+1)*4))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# middle.save('middle.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
