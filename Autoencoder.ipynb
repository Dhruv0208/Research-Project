{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handled-prayer",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/Dhruv0208/Research-Project/blob/main/Autoencoder.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on github\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/Dhruv0208/Research-Project/Autoencoder.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "</td></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from imutils import paths\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Path = \"/media/beast/Samsung_T5/nVidia_Research_Work\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-portrait",
   "metadata": {},
   "source": [
    "## DATA IN FORMAT\n",
    " Base_Path<br>\n",
    "&emsp;&emsp;|-train2017<br>\n",
    "&emsp;&emsp;|-val2017<br>\n",
    "&emsp;&emsp;|-annotations_val(without_column_names).csv<br>\n",
    "&emsp;&emsp;|-annotations_train(without_column_names).csv<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-income",
   "metadata": {},
   "source": [
    "for csv files  first run \"Preparing_Dataset.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Images_Path = os.path.sep.join([Base_Path, 'train2017'])\n",
    "Val_Images_Path = os.path.sep.join([Base_Path, 'val2017'])\n",
    "Annots_Val_Path = os.path.sep.join([Base_Path, 'annotations_val(without_column_names).csv'])\n",
    "Annots_Train_Path = os.path.sep.join([Base_Path, 'annotations_train(without_column_names).csv'])\n",
    "# Lb_Path = os.path.sep.join([Base_Path, 'lb.pickle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-pendant",
   "metadata": {},
   "source": [
    "## Setting Up training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading dataset....\")\n",
    "data_train = []\n",
    "# labels_train = []\n",
    "# bboxes_train = []\n",
    "# image_Paths_train = []\n",
    "rows = open(Annots_Train_Path).read().strip().split(\"\\n\")\n",
    "for row in rows:\n",
    "    row = row.split(\",\")\n",
    "    (filename, startX, startY, endX, endY, cat_ID, cat_Name) = row\n",
    "    imagePath = os.path.sep.join([Train_Images_Path, filename])\n",
    "    image = cv2.imread(imagePath)\n",
    "    (h, w) = image.shape[:2]\n",
    "    startX = float(startX) / w\n",
    "    startY = float(startY) / h\n",
    "    endX = float(endX) / w\n",
    "    endY = float(endY) / h\n",
    "    image = load_img(imagePath, target_size = (512,512))\n",
    "    image = img_to_array(image)\n",
    "    data_train.append(image)\n",
    "#     labels_train.append(cat_Name)\n",
    "#     bboxes_train.append((startX, startY, endX, endY))\n",
    "#     image_Paths_train.append(imagePath)\n",
    "    print(len(data_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-delicious",
   "metadata": {},
   "source": [
    "## Setting up validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading dataset....\")\n",
    "data_val = []\n",
    "# labels_train = []\n",
    "# bboxes_train = []\n",
    "# image_Paths_train = []\n",
    "rows = open(Annots_Val_Path).read().strip().split(\"\\n\")\n",
    "for row in rows:\n",
    "    row = row.split(\",\")\n",
    "    (filename, startX, startY, endX, endY, cat_ID, cat_Name) = row\n",
    "    imagePath = os.path.sep.join([Val_Images_Path, filename])\n",
    "    image = cv2.imread(imagePath)\n",
    "    (h, w) = image.shape[:2]\n",
    "    startX = float(startX) / w\n",
    "    startY = float(startY) / h\n",
    "    endX = float(endX) / w\n",
    "    endY = float(endY) / h\n",
    "    image = load_img(imagePath, target_size = (512,512))\n",
    "    image = img_to_array(image)\n",
    "    data_val.append(image)\n",
    "#     labels_train.append(cat_Name)\n",
    "#     bboxes_train.append((startX, startY, endX, endY))\n",
    "#     image_Paths_train.append(imagePath)\n",
    "    print(len(data_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-burning",
   "metadata": {},
   "source": [
    "## Saving variables to prevent loading data again and again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "# dill.dump_session('autoencoder_variables.db')\n",
    "# dill.load_session('autoencoder_variables.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-license",
   "metadata": {},
   "source": [
    "converting images into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data_train, dtype=\"float32\") / 255.0\n",
    "(val_images) = np.array(data_val, dtype=\"float32\") / 255.0\n",
    "# labels = np.array(labels)\n",
    "# bboxes = np.array(bboxes, dtype = \"float32\")\n",
    "# image_Paths = np.array(image_Paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-pillow",
   "metadata": {},
   "source": [
    "splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, test_images) = train_test_split(data, test_size=0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-duration",
   "metadata": {},
   "source": [
    "## Preparing autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(512,512,3))\n",
    "x = layers.Conv2D(256, (3,3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2,2), padding = 'same')(x)\n",
    "x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "x = layers.Conv2D(8, (3,3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(16, (3,3), activation='relu', padding = 'same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(16, (3,3), activation = 'relu', padding = 'same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(32, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(64, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(128, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "x = layers.Conv2D(256, (3,3), activation = 'relu', padding= 'same')(x)\n",
    "x = layers.UpSampling2D((2,2))(x)\n",
    "decoded = layers.Conv2D(3, (3,3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(autoencoder, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(train_images, train_images, epochs = 1, shuffle = True, verbose=1, validation_data=(val_images, val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "plt.figure(figsize=(32,32))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i+1)\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i+n+1)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
